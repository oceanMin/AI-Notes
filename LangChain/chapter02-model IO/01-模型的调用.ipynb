{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. 模型调用的分类\n",
    "\n",
    "角度1：按照模型功能的不同\n",
    "\n",
    "非对话模型：（LLMs、Text Model）\n",
    "\n",
    "对话模型：（Chat Models）  （推荐）\n",
    "\n",
    "嵌入模型：（Embedding Models）\n",
    "\n",
    "\n",
    "角度2：按照模型调用时，参数书写的位置不同（api-key、base_url、model_name）\n",
    "\n",
    "硬编码的方式：将参数书写在代码中\n",
    "\n",
    "使用环境变量的方式\n",
    "\n",
    "使用配置文件的方式（推荐）\n",
    "\n",
    "\n",
    "角度3：具体API的调用\n",
    "\n",
    "使用LangChain提供的API（推荐）\n",
    "\n",
    "使用OpenAI官方的API\n",
    "\n",
    "使用其他平台提供的API\n",
    "\n",
    "# 2、角度1：非对话模型的调用"
   ],
   "id": "81f2d16e3775551e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tempfile import template\n",
    "\n",
    "# 安装必要的包（如果还没安装）\n",
    "# !pip install langchain-ollama\n",
    "\n",
    "from langchain_ollama import OllamaLLM  # 替换 OpenAI\n",
    "# 不再需要 dotenv 和 os.environ 设置 API Key\n",
    "\n",
    "# 创建本地 Ollama 模型实例\n",
    "llm = OllamaLLM(\n",
    "    model=\"deepseek-r1:7b\",  # 使用你已有的模型\n",
    "    # 或使用其他模型：\"llama3.2\", \"qwen2.5:7b\" 等\n",
    "    temperature=0.7,  # 创造性，0-1\n",
    "    num_predict=512   # 最大生成长度\n",
    ")\n",
    "\n",
    "# 调用模型\n",
    "str = llm.invoke('请写一首关于春天的诗')\n",
    "print(str)"
   ],
   "id": "75ee00473dfc6589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2、角度1：对话模型的调用",
   "id": "3e60011d16c7d01f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "########核心代码############\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "messages = [\n",
    " SystemMessage(content=\"我是人工智能助手，我叫小智\"),\n",
    " HumanMessage(content=\"你好，我是小明，很高兴认识你\")\n",
    "]\n",
    "response = chat_model.invoke(messages) # 输入消息列表\n",
    "print(type(response)) # <class 'langchain_core.messages.ai.AIMessage'>\n",
    "print(response.content)\n"
   ],
   "id": "e60ef7d8e5f00d9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2、角度1：嵌入模型的调用",
   "id": "55508e6cb6d12b2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 安装必要的包（如果还没安装）\n",
    "# !pip install langchain-community\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings  # 替换 OpenAIEmbeddings\n",
    "# 不再需要 dotenv 和 API Key\n",
    "\n",
    "# 创建本地 Ollama embeddings 模型\n",
    "embeddings_model = OllamaEmbeddings(\n",
    "    model=\"llama3.2\"  # 或其他模型：\"deepseek-r1:7b\", \"nomic-embed-text\" 等\n",
    ")\n",
    "\n",
    "# 生成嵌入向量\n",
    "res1 = embeddings_model.embed_query('我是文档中的数据')\n",
    "print(f\"向量维度: {len(res1)}\")\n",
    "print(f\"前10个值: {res1[:10]}\")  # 只打印前10个值，否则太长"
   ],
   "id": "3620fb5be935bcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3、角度额2\n",
    "\n",
    "## 1.硬编码的方式\n",
    "\n",
    "以对话模型为例："
   ],
   "id": "96ab5a494749016d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1、获取大模型\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=\"sk-I8eV20Ba0WFknZpli3ibGuqy9sXq9y5QD3x5RVgnLeBhAvzd\",\n",
    "    base_url=\"https://api.openai-proxy.org/v1\"\n",
    ")\n",
    "\n",
    "# 2、调用大模型\n",
    "response = chat_model.invoke('请介绍一下你自己?')\n",
    "\n",
    "# 3、输出响应文本\n",
    "print(response.content)"
   ],
   "id": "521a4d1c6ee76cee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 使用环境变量的方式",
   "id": "66b57a2ec559b731"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1、获取大模型\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=os.environ[\"OPENAI_BASE_URL\"],\n",
    ")\n",
    "\n",
    "# 2、调用大模型\n",
    "response = chat_model.invoke('请介绍一下你自己?')\n",
    "\n",
    "# 3、输出响应文本\n",
    "print(response.content)"
   ],
   "id": "ddaad8bd3b60bad9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3.3 使用配置文件的方式\n",
    "\n",
    "创建.env的配置文件\n",
    "\n",
    "方式1："
   ],
   "id": "427ea961925b3672"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T07:41:45.370377100Z",
     "start_time": "2026-02-06T07:41:40.285394800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "# os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "\n",
    "# 1、获取大模型\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY1\"),\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    ")\n",
    "\n",
    "# 2、调用大模型\n",
    "response = chat_model.invoke('什么是langchain?')\n",
    "\n",
    "# 3、输出响应文本\n",
    "print(response.content)"
   ],
   "id": "c55edb13b68186f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain 是一个开源框架，旨在简化和增强与语言模型（例如 GPT-3、GPT-4 等）的交互。它提供了一系列工具和模块，开发者可以利用这些工具来构建应用程序，处理自然语言任务。\n",
      "\n",
      "LangChain 的主要功能包括：\n",
      "\n",
      "1. **模型集成**：支持多个语言模型，方便开发者选择适合的模型进行集成。\n",
      "2. **链式调用**：允许用户将多个处理步骤（如数据预处理、模型调用、后处理）串联起来，形成复杂的工作流。\n",
      "3. **上下文管理**：提供更好的上下文管理，确保模型在进行对话或处理任务时能更好地理解和利用历史信息。\n",
      "4. **数据连接**：支持从外部数据源（如数据库、API 等）提取信息，以增强模型的响应能力。\n",
      "5. **工具扩展**：允许开发者创建自定义工具和模块，以满足特定的应用需求。\n",
      "\n",
      "LangChain 非常适合构建对话应用、问答系统、内容生成工具等各种基于语言模型的应用。通过使用 LangChain，开发者可以更加高效地开发和维护自己的应用程序，同时利用先进的自然语言处理技术。\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "方式2：",
   "id": "97ffe5d5a9b3bcb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T08:11:00.457401100Z",
     "start_time": "2026-02-06T08:10:54.468163600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# 加载.env配置文件\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "\n",
    "# 1、获取大模型\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", # 默认使用的是gpt-3.5-turbo模型\n",
    "    #当没有显示的声明base_url和api_key的时候，默认会从环境变量中查找\n",
    "    max_tokens=500, #最大token数\n",
    "    temperature=0.7,    #温度，控制文本生成的“随机性”取值范围0~1，\n",
    ")\n",
    "\n",
    "# 2、调用大模型\n",
    "response = chat_model.invoke('什么是langchain?')\n",
    "\n",
    "# 3、输出响应文本\n",
    "print(response.content)"
   ],
   "id": "a15a84d8780ba4f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain 是一个开源框架，旨在帮助开发者构建基于语言模型的应用程序。它提供了一系列工具和组件，使得与大型语言模型（如 OpenAI 的 GPT 系列）进行交互变得更加简单和高效。LangChain 的设计使得开发者能够快速构建复杂的应用，如对话系统、自动化内容生成、知识提取等。\n",
      "\n",
      "LangChain 的核心特性包括：\n",
      "\n",
      "1. **模块化设计**：LangChain 提供了多个模块，可以单独或组合使用，这些模块包括用于数据加载、模型接口、链式执行等功能。\n",
      "\n",
      "2. **链式调用**：开发者可以创建“链”，将多个操作串联起来，以实现更复杂的功能。例如，用户输入可以经过预处理、模型推理，并最终得到输出结果。\n",
      "\n",
      "3. **支持多种模型**：LangChain 支持多种语言模型和后端，使得开发者可以选择最合适的模型来满足特定需求。\n",
      "\n",
      "4. **集成数据源**：LangChain 允许用户将数据源（如数据库、API、文档等）与语言模型结合，以便模型可以利用更多上下文信息。\n",
      "\n",
      "5. **用于知识管理**：LangChain 有助于构建知识管理系统，允许用户在自定义知识库中提问并获取基于该知识库的答案。\n",
      "\n",
      "通过这些功能，LangChain 可以帮助开发者快速构建和原型化基于语言理解的应用，推动自然语言处理技术的实际应用。\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY1\")\n",
    "os.environ[\"OPENAI_BASE_URL\"] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "messages = [SystemMessage(content=\"你是一位哲学家\"),\n",
    "            HumanMessage(content=\"你好，请介绍一下你自己，包括自己名字\"),\n",
    "            AIMessage(content=\"我叫小智，能帮你解决各种哲学问题\")]\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "print(response.content)\n",
    "print(messages)"
   ],
   "id": "5ef44aef78a15e2d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
